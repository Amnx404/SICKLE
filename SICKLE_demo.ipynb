{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mbkt9ohRPDh"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1vKxH3JJ6TLv63y3kwTZ7VQzVo2EJPZqg#scrollTo=1mbkt9ohRPDh\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5TtXswcBvWE"
      },
      "source": [
        "# Clone Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXqCUIR0DwwR",
        "outputId": "4c200996-66ee-4d37-a2aa-6d8b8ff0b17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SICKLE'...\n",
            "remote: Enumerating objects: 153, done.\u001b[K\n",
            "remote: Counting objects: 100% (153/153), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 153 (delta 69), reused 137 (delta 59), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (153/153), 2.17 MiB | 9.49 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Depanshu-Sani/SICKLE.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nw1QtTJu2cZ",
        "outputId": "c9fd9726-ff06-409b-8db5-2e3a783965d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/SICKLE\n"
          ]
        }
      ],
      "source": [
        "%cd SICKLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHGOJAwXB7UN"
      },
      "source": [
        "# Get the dataset\n",
        "### You have to get the access using [this](https://docs.google.com/forms/d/e/1FAIpQLSdq7Dcj5FF1VmlKozrQ7XNoq006iVKrUIMTK2jReBJDuO1N2g/viewform) form. After that create a shortcut of drive folder to your drive and use the path below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JzHcnVPpFuH",
        "outputId": "e9f30e10-5132-40a4-9b8c-d08ace375d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q2HRAOioDcLW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip /content/drive/MyDrive/WACV\\ 2024/sickle_toy_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "paYskH1pRipb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip /content/drive/MyDrive/WACV\\ 2024/weights.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G3MnxqYB-lE"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zNN50BK_OYGI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZyIUn2cbQA2I"
      },
      "outputs": [],
      "source": [
        "! chmod 777 ./*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GL84NiqP8SL",
        "outputId": "addeb202-122a-4add-efc9-bde7ebd96c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> SEEDING DONE 0\n",
            "Namespace(model='unet3d', encoder_widths=[64, 128], decoder_widths=[32, 128], out_conv=[32, 16], str_conv_k=4, str_conv_s=2, str_conv_p=1, agg_mode='att_group', encoder_norm='group', n_head=16, d_model=256, d_k=4, device='cuda', num_workers=8, seed=0, epochs=100, batch_size=32, lr=0.1, num_classes=1, ignore_index=-999, pad_value=0, padding_mode='reflect', resume='', run_id='', wandb=False, satellites={'S1': {'bands': ['VV', 'VH'], 'rgb_bands': [0, 1, 0], 'mask_res': 10, 'img_size': (32, 32)}, 'S2': {'bands': ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12'], 'rgb_bands': [3, 2, 1], 'mask_res': 10, 'img_size': (32, 32)}}, run_name='[S1,S2]_unet3d', exp_name='sowing_date', task='sowing_date', actual_season=False, data_dir='sickle_toy_dataset/', use_augmentation=True, cache=False, run_path='runs/wacv_2024_seed0/sowing_date/[S1,S2]_unet3d', primary_sat='S1', img_size=(32, 32))\n",
            "-----------S1------------\n",
            "Samples Shape torch.Size([28, 23, 2, 32, 32]) Masks Shape torch.Size([28, 32, 32])\n",
            "dates tensor([  4,  16,  28,  34,  40,  46,  52,  58,  64,  70,  76,  82,  88,  94,\n",
            "        100, 106, 112, 118, 124, 136, 148, 160, 172])\n",
            "Samples tensor([-33.6130, -32.9389, -32.4642,  ...,  -2.2399,  -2.1667,  -2.0488])\n",
            "Masks tensor([-999.,    0.,    1.,    2.,    6.,    8.,    9.,   10.,   11.,   13.,\n",
            "          33.], dtype=torch.float64)\n",
            "-----------S2------------\n",
            "Samples Shape torch.Size([28, 72, 12, 32, 32]) Masks Shape torch.Size([28, 32, 32])\n",
            "dates tensor([  3,   8,  13,  18,  23,  28,  33,  38,  43,  48,  53,  58,  63,  68,\n",
            "         73,  78,  83,  88,  93,  98, 103, 108, 113, 118, 123, 128, 133, 138,\n",
            "        143, 148, 153, 158, 163, 168, 173, 178,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0])\n",
            "Samples tensor([    0.0000,    55.5926,    60.2842,  ..., 16229.5215, 16229.7607,\n",
            "        16229.9990])\n",
            "Masks tensor([-999.,    0.,    1.,    2.,    6.,    8.,    9.,   10.,   11.,   13.,\n",
            "          33.], dtype=torch.float64)\n",
            "Train 28, Val 6, Test 0\n",
            "TOTAL TRAINABLE PARAMETERS : 4644385\n",
            "EPOCH 1/100\n",
            "train: 100% 1/1 [00:09<00:00,  9.21s/it, Loss=7.8221, gpu_mem=7.26 GB]\n",
            "Epoch time : 9.6s\n",
            "Validation . . . \n",
            "val: 100% 1/1 [00:02<00:00,  2.32s/it, Loss=31363504757800960.0000, gpu_mem=7.26 GB]\n",
            "Epoch time : 2.7s\n",
            "Val RMSE: 31363504757800960.0000 | Val MAE: 31017087728091136.0000 | Val MAPE: 169492277624832.0000\n",
            "Valid Score Improved (inf ---> 31017087728091136.0000)\n",
            "EPOCH 2/100\n",
            "train:   0% 0/1 [00:05<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SICKLE/train.py\", line 688, in <module>\n",
            "    main(CFG)\n",
            "  File \"/content/SICKLE/train.py\", line 428, in main\n",
            "    train_loss, train_metrics = iterate(\n",
            "  File \"/content/SICKLE/train.py\", line 180, in iterate\n",
            "    for i, batch in pbar:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1195, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1316, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1282, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1120, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 424, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!./train.sh sickle_toy_dataset/ [S1,S2] unet3d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS1ZLfNCCDpz"
      },
      "source": [
        "# Main Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AdybITehOFjt"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import copy\n",
        "import pprint\n",
        "\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Custom import\n",
        "from utils.dataset import SICKLE_Dataset\n",
        "from utils import utae_utils, model_utils\n",
        "from utils.weight_init import weight_init\n",
        "from utils.metric import get_metrics, RMSELoss\n",
        "from evaluate import iterate as val_iter\n",
        "from train import iterate as train_iter\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torchnet as tnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4RRUNDISc6mY"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "    # For reproducibility\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception as e:\n",
        "        print(\"Can not use deterministic algorithm. Error: \", e)\n",
        "    print(f\"> SEEDING DONE {seed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oT_7M1Ykq-GA"
      },
      "outputs": [],
      "source": [
        "def get_data_loaders():\n",
        "  # Dataset definition\n",
        "    data_dir = CFG.data_dir\n",
        "    df = pd.read_csv(os.path.join(data_dir,\"sickle_dataset_tabular.csv\"))\n",
        "\n",
        "    if CFG.task != \"crop_type\":\n",
        "        df = df[df.YIELD > 0].reset_index(drop=True)\n",
        "\n",
        "    train_df = df[df.SPLIT == \"train\"].reset_index(drop=True)\n",
        "    val_df = df[df.SPLIT == \"val\"].reset_index(drop=True)\n",
        "    test_df = df[df.SPLIT == \"test\"].reset_index(drop=True)\n",
        "\n",
        "    dt_args = dict(\n",
        "        data_dir=data_dir,\n",
        "        satellites=CFG.satellites,\n",
        "        ignore_index=CFG.ignore_index,\n",
        "        transform=CFG.use_augmentation,\n",
        "        actual_season=CFG.actual_season\n",
        "    )\n",
        "\n",
        "    dt_train = SICKLE_Dataset(df=train_df, phase=\"train\", **dt_args)\n",
        "    dt_args = dict(\n",
        "        data_dir=data_dir,\n",
        "        satellites=CFG.satellites,\n",
        "        ignore_index=CFG.ignore_index,\n",
        "        actual_season=CFG.actual_season\n",
        "    )\n",
        "    dt_val = SICKLE_Dataset(df=val_df, **dt_args, )\n",
        "    dt_test = SICKLE_Dataset(df=test_df, **dt_args)\n",
        "\n",
        "    collate_fn = lambda x: utae_utils.pad_collate(x, pad_value=CFG.pad_value)\n",
        "    train_loader = data.DataLoader(\n",
        "        dt_train,\n",
        "        batch_size=CFG.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=CFG.num_workers,\n",
        "    )\n",
        "    val_loader = data.DataLoader(\n",
        "        dt_val,\n",
        "        batch_size=CFG.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=CFG.num_workers,\n",
        "    )\n",
        "    test_loader = data.DataLoader(\n",
        "        dt_test,\n",
        "        batch_size=CFG.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=CFG.num_workers,\n",
        "    )\n",
        "    batch_data, masks = next(iter(train_loader))\n",
        "    for sat in CFG.satellites.keys():\n",
        "        (samples, dates) = batch_data[sat]\n",
        "        print(f\"-----------{sat}------------\")\n",
        "        print(\"Samples Shape\", samples.shape, \"Masks Shape\", masks[\"crop_type\"].shape)\n",
        "        print(\"dates\", dates[0])\n",
        "        print(\"Samples\", torch.unique(samples[0]))\n",
        "        print(\"Masks\", torch.unique(masks[CFG.task]))\n",
        "\n",
        "    print(\n",
        "        \"Train {}, Val {}, Test {}\".format(len(dt_train), len(dt_val), len(dt_test))\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ECFlBKJmUIh7"
      },
      "outputs": [],
      "source": [
        "def val(CFG):\n",
        "    device = CFG.device\n",
        "    train_loader, val_loader, test_loader = get_data_loaders()\n",
        "\n",
        "    model = model_utils.Fusion_model(CFG)\n",
        "    model.apply(weight_init)\n",
        "    model = model.to(device)\n",
        "    CFG.N_params = utae_utils.get_ntrainparams(model)\n",
        "    print(\"TOTAL TRAINABLE PARAMETERS :\", CFG.N_params)\n",
        "\n",
        "    # Optimizer, Loss and Scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n",
        "    if CFG.task == \"crop_type\":\n",
        "        criterion = nn.CrossEntropyLoss(ignore_index=CFG.ignore_index,\n",
        "                                        weight=torch.tensor([0.62013, 0.37987])).to(device=CFG.device, dtype=torch.float32)\n",
        "    else:\n",
        "        criterion = RMSELoss(ignore_index=CFG.ignore_index)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=3 * CFG.epochs // 4, eta_min=1e-4)\n",
        "\n",
        "    best_checkpoint = torch.load(\n",
        "        os.path.join(\n",
        "            CFG.best_path, \"checkpoint_best.pth.tar\"\n",
        "        )\n",
        "    )\n",
        "    model.load_state_dict(best_checkpoint[\"model\"])\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, val_metrics, _ = val_iter(\n",
        "        model,\n",
        "        data_loader=val_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        mode=\"val\",\n",
        "        device=device,\n",
        "        task=CFG.task,\n",
        "        log=True,\n",
        "        CFG=CFG,\n",
        "    )\n",
        "    print(f\"val Result {CFG.task}\")\n",
        "    if CFG.task == \"crop_type\":\n",
        "        # val metric\n",
        "        val_f1_macro, val_acc, val_iou, val_f1_paddy, val_f1_non_paddy, \\\n",
        "        val_acc_paddy, val_acc_non_paddy, val_iou_paddy, val_iou_non_paddy, _ = val_metrics\n",
        "        deciding_metric = val_f1_macro\n",
        "        # log and print metrics\n",
        "        print(\n",
        "            f\"F1: {val_f1_macro:0.4f} | Paddy F1: {val_f1_paddy:0.4f} | Non-Paddy F1: {val_f1_non_paddy:0.4f} \\nAcc:{val_acc:0.4f} | Paddy Acc: {val_acc_paddy:0.4f} | Non-Paddy Acc: {val_acc_non_paddy:0.4f}\\niou:{val_iou:0.4f} | Paddy iou: {val_iou_paddy:0.4f} | Non-Paddy iou: {val_iou_non_paddy:0.4f}\")\n",
        "\n",
        "    else:\n",
        "        # val metrics\n",
        "        val_rmse, val_mae, val_mape = val_metrics\n",
        "        print(f\"val RMSE: {val_rmse:0.4f} | val MAE: {val_mae:0.4f} | val MAPE: {val_mape:0.4f}\")\n",
        "        vallog = {\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_rmse\": val_rmse.item(),\n",
        "            \"val_mae\": val_mae.item(),\n",
        "            \"val_mape\": val_mape.item(),\n",
        "        }\n",
        "\n",
        "def train(CFG):\n",
        "    device = CFG.device\n",
        "\n",
        "    train_loader, val_loader, test_loader = get_data_loaders()\n",
        "\n",
        "    model = model_utils.Fusion_model(CFG)\n",
        "    model.apply(weight_init)\n",
        "    model = model.to(device)\n",
        "    CFG.N_params = utae_utils.get_ntrainparams(model)\n",
        "    print(\"TOTAL TRAINABLE PARAMETERS :\", CFG.N_params)\n",
        "\n",
        "    # Optimizer, Loss and Scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n",
        "    if CFG.task == \"crop_type\":\n",
        "        criterion = nn.CrossEntropyLoss(ignore_index=CFG.ignore_index,\n",
        "                                        weight=torch.tensor([0.62013, 0.37987])).to(device=CFG.device, dtype=torch.float32)\n",
        "    else:\n",
        "        criterion = RMSELoss(ignore_index=CFG.ignore_index)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=3 * CFG.epochs // 4, eta_min=1e-4)\n",
        "\n",
        "    # Training loop\n",
        "    trainlog = {}\n",
        "    best_metric = 0 if CFG.task == \"crop_type\" else torch.inf\n",
        "    for epoch in range(1, CFG.epochs + 1):\n",
        "        print(\"EPOCH {}/{}\".format(epoch, CFG.epochs))\n",
        "        model.train()\n",
        "        train_loss, train_metrics = train_iter(\n",
        "            model,\n",
        "            data_loader=train_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            scheduler=scheduler,\n",
        "            mode=\"train\",\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            task=CFG.task,\n",
        "            CFG = CFG,\n",
        "        )\n",
        "\n",
        "        print(\"Validation . . . \")\n",
        "        model.eval()\n",
        "        val_loss, val_metrics = train_iter(\n",
        "            model,\n",
        "            data_loader=val_loader,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            mode=\"val\",\n",
        "            device=device,\n",
        "            task=CFG.task,\n",
        "            CFG = CFG,\n",
        "\n",
        "        )\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        if CFG.task == \"crop_type\":\n",
        "            # train metrics\n",
        "            train_f1_macro, train_acc, train_iou, train_f1_paddy, train_f1_non_paddy, \\\n",
        "            train_acc_paddy, train_acc_non_paddy, train_iou_paddy, train_iou_non_paddy, _ = train_metrics\n",
        "            # val metric\n",
        "            val_f1_macro, val_acc, val_iou, val_f1_paddy, val_f1_non_paddy, \\\n",
        "            val_acc_paddy, val_acc_non_paddy, val_iou_paddy, val_iou_non_paddy, _ = val_metrics\n",
        "            deciding_metric = val_f1_macro\n",
        "            # log and print metrics\n",
        "            print(\n",
        "                f\"F1: {val_f1_macro:0.4f} | Paddy F1: {val_f1_paddy:0.4f} | Non-Paddy F1: {val_f1_non_paddy:0.4f} \\nAcc:{val_acc:0.4f} | Paddy Acc: {val_acc_paddy:0.4f} | Non-Paddy Acc: {val_acc_non_paddy:0.4f}\\niou:{val_iou:0.4f} | Paddy iou: {val_iou_paddy:0.4f} | Non-Paddy iou: {val_iou_non_paddy:0.4f}\")\n",
        "        else:\n",
        "            # train metrics\n",
        "            train_rmse, train_mae, train_mape = train_metrics\n",
        "            # val metrics\n",
        "            val_rmse, val_mae, val_mape = val_metrics\n",
        "            deciding_metric = val_mae\n",
        "            print(f\"Val RMSE: {val_rmse:0.4f} | Val MAE: {val_mae:0.4f} | Val MAPE: {val_mape:0.4f}\")\n",
        "\n",
        "        if (deciding_metric > best_metric and CFG.task == \"crop_type\") or (\n",
        "                deciding_metric < best_metric and CFG.task != \"crop_type\"):\n",
        "            print(f\"Valid Score Improved ({best_metric:0.4f} ---> {deciding_metric:0.4f})\")\n",
        "            best_metric = deciding_metric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ConYCm6eNoOt",
        "outputId": "e55e12cc-18e0-44ee-a736-6326086392fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> SEEDING DONE 0\n"
          ]
        }
      ],
      "source": [
        "class CFG:\n",
        "    model='utae'\n",
        "    encoder_widths=[64, 128]\n",
        "    decoder_widths=[32, 128]\n",
        "    out_conv=[32, 16]\n",
        "    str_conv_k=4\n",
        "    str_conv_s=2\n",
        "    str_conv_p=1\n",
        "    agg_mode='att_group'\n",
        "    encoder_norm='group'\n",
        "    n_head=16\n",
        "    d_model=256\n",
        "    d_k=4\n",
        "    padding_mode='reflect'\n",
        "    # SICKLE Specific Parameters\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    num_workers=2\n",
        "    seed=0\n",
        "    epochs=10\n",
        "    batch_size=32\n",
        "    lr=0.1\n",
        "    num_classes=2\n",
        "    ignore_index=-999\n",
        "    pad_value=0\n",
        "    resume=''\n",
        "    run_id=''\n",
        "    debug=False\n",
        "    actual_season=False\n",
        "    use_augmentation=True\n",
        "    cache=False\n",
        "\n",
        "\n",
        "CFG.satellites=[\"S1\"]\n",
        "CFG.task='crop_yield'\n",
        "CFG.run_name = f'{CFG.satellites}_{CFG.model}'\n",
        "CFG.data_dir='./dataset/'\n",
        "CFG.run_path='./runs/wacv_2024/crop_type/[S1]_utae'\n",
        "CFG.best_path='./runs/wacv_2024/crop_type/[S1]_utae'\n",
        "CFG.exp_name = CFG.task\n",
        "\n",
        "CFG.run_path = f\"runs/wacv_2024_seed{CFG.seed}/{CFG.exp_name}/{CFG.run_name}\"\n",
        "\n",
        "satellite_metadata = {\n",
        "    \"S2\": {\n",
        "        \"bands\": ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12'],\n",
        "        \"rgb_bands\": [3, 2, 1],\n",
        "        \"mask_res\": 10,\n",
        "        \"img_size\": (32, 32),\n",
        "    },\n",
        "    \"S1\": {\n",
        "        \"bands\": ['VV', 'VH'],\n",
        "        \"rgb_bands\": [0, 1, 0],\n",
        "        \"mask_res\": 10,\n",
        "        \"img_size\": (32, 32),\n",
        "    },\n",
        "    \"L8\": {\n",
        "        \"bands\": [\"SR_B1\", \"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B6\", \"SR_B7\", \"ST_B10\"],\n",
        "        \"rgb_bands\": [3, 2, 1],\n",
        "        \"mask_res\": 10,\n",
        "        \"img_size\": (32, 32),\n",
        "    },\n",
        "}\n",
        "\n",
        "required_sat_data = {}\n",
        "for satellite in CFG.satellites:\n",
        "    required_sat_data[satellite] = satellite_metadata[satellite]\n",
        "CFG.satellites = required_sat_data\n",
        "\n",
        "# first satellie is primary, img_size and mask_res is decided by it\n",
        "CFG.primary_sat =list(required_sat_data.keys())[0]\n",
        "CFG.img_size = required_sat_data[CFG.primary_sat][\"img_size\"]\n",
        "set_seed(CFG.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhWHvUiaBptZ"
      },
      "source": [
        "# Validation and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nU-p2YZ5TBUo",
        "outputId": "4fb8d660-dccc-4a4f-ba02-b2c99597f559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------S1------------\n",
            "Samples Shape torch.Size([32, 23, 2, 32, 32]) Masks Shape torch.Size([32, 32, 32])\n",
            "dates tensor([  3,   9,  15,  21,  27,  33,  45,  57,  69,  81,  93, 105, 117, 129,\n",
            "        141, 153, 165, 177,   0,   0,   0,   0,   0])\n",
            "Samples tensor([-2.5294e+01, -2.5246e+01, -2.4161e+01,  ...,  0.0000e+00,\n",
            "         5.1325e-03,  5.9624e-01])\n",
            "Masks tensor([-999.,    0.,    1.], dtype=torch.float64)\n",
            "Train 1937, Val 227, Test 206\n",
            "TOTAL TRAINABLE PARAMETERS : 1060738\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/SICKLE/runs/wacv_2024/crop_type/[S1]_utae/checkpoint_best.pth.tar'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[10], line 20\u001b[0m, in \u001b[0;36mval\u001b[0;34m(CFG)\u001b[0m\n\u001b[1;32m     17\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m RMSELoss(ignore_index\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mignore_index)\n\u001b[1;32m     18\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m CosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m CFG\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m, eta_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m best_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint_best.pth.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(best_checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
            "File \u001b[0;32m~/miniconda3/envs/sickle/lib/python3.9/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[0;32m~/miniconda3/envs/sickle/lib/python3.9/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[0;32m~/miniconda3/envs/sickle/lib/python3.9/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/SICKLE/runs/wacv_2024/crop_type/[S1]_utae/checkpoint_best.pth.tar'"
          ]
        }
      ],
      "source": [
        "val(CFG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFkh3EKZpuit",
        "outputId": "72150a65-6850-4e67-de01-c7372d59ef3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------S1------------\n",
            "Samples Shape torch.Size([32, 23, 2, 32, 32]) Masks Shape torch.Size([32, 32, 32])\n",
            "dates tensor([  9,  21,  33,  57,  69,  81,  93, 105, 117, 129, 141, 153, 165, 177,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
            "Samples tensor([-49.4443, -44.4791, -43.4562,  ...,  -0.8202,  -0.5070,   0.0000])\n",
            "Masks tensor([-999.,    0.,    1.], dtype=torch.float64)\n",
            "Train 194, Val 23, Test 0\n",
            "TOTAL TRAINABLE PARAMETERS : 1060738\n",
            "EPOCH 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.23it/s, Loss=0.7349, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.8s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "val: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, Loss=1443.5586, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.0s\n",
            "F1: 0.1511 | Paddy F1: 0.3021 | Non-Paddy F1: 0.0000 \n",
            "Acc:0.1780 | Paddy Acc: 1.0000 | Non-Paddy Acc: 0.0000\n",
            "iou:0.0890 | Paddy iou: 0.1780 | Non-Paddy iou: 0.0000\n",
            "Valid Score Improved (0.0000 ---> 0.1511)\n",
            "EPOCH 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s, Loss=0.7317, gpu_mem=3.77 GB]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.4s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it, Loss=1157.7885, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.3s\n",
            "F1: 0.1511 | Paddy F1: 0.3021 | Non-Paddy F1: 0.0000 \n",
            "Acc:0.1780 | Paddy Acc: 1.0000 | Non-Paddy Acc: 0.0000\n",
            "iou:0.0890 | Paddy iou: 0.1780 | Non-Paddy iou: 0.0000\n",
            "EPOCH 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s, Loss=0.2880, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.4s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "val: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, Loss=680.4742, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.0s\n",
            "F1: 0.1511 | Paddy F1: 0.3021 | Non-Paddy F1: 0.0000 \n",
            "Acc:0.1780 | Paddy Acc: 1.0000 | Non-Paddy Acc: 0.0000\n",
            "iou:0.0890 | Paddy iou: 0.1780 | Non-Paddy iou: 0.0000\n",
            "EPOCH 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s, Loss=0.5255, gpu_mem=3.77 GB]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.2s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it, Loss=76.3615, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.3s\n",
            "F1: 0.1511 | Paddy F1: 0.3021 | Non-Paddy F1: 0.0000 \n",
            "Acc:0.1780 | Paddy Acc: 1.0000 | Non-Paddy Acc: 0.0000\n",
            "iou:0.0890 | Paddy iou: 0.1780 | Non-Paddy iou: 0.0000\n",
            "EPOCH 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.29it/s, Loss=0.6793, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.6s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "val: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it, Loss=10.2848, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.4s\n",
            "F1: 0.2541 | Paddy F1: 0.3250 | Non-Paddy F1: 0.1832 \n",
            "Acc:0.2609 | Paddy Acc: 1.0000 | Non-Paddy Acc: 0.1009\n",
            "iou:0.1475 | Paddy iou: 0.1940 | Non-Paddy iou: 0.1009\n",
            "Valid Score Improved (0.1511 ---> 0.2541)\n",
            "EPOCH 6/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s, Loss=0.6095, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.5s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "val: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it, Loss=0.9078, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.3s\n",
            "F1: 0.4166 | Paddy F1: 0.3399 | Non-Paddy F1: 0.4933 \n",
            "Acc:0.4267 | Paddy Acc: 0.8295 | Non-Paddy Acc: 0.3395\n",
            "iou:0.2661 | Paddy iou: 0.2048 | Non-Paddy iou: 0.3274\n",
            "Valid Score Improved (0.2541 ---> 0.4166)\n",
            "EPOCH 7/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s, Loss=0.3811, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.4s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "val: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, Loss=0.7251, gpu_mem=3.77 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.0s\n",
            "F1: 0.3113 | Paddy F1: 0.3398 | Non-Paddy F1: 0.2827 \n",
            "Acc:0.3124 | Paddy Acc: 0.9943 | Non-Paddy Acc: 0.1648\n",
            "iou:0.1846 | Paddy iou: 0.2047 | Non-Paddy iou: 0.1646\n",
            "EPOCH 8/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s, Loss=0.7298, gpu_mem=4.31 GB]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.4s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it, Loss=0.6530, gpu_mem=4.31 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.3s\n",
            "F1: 0.4308 | Paddy F1: 0.3772 | Non-Paddy F1: 0.4843 \n",
            "Acc:0.4358 | Paddy Acc: 0.9602 | Non-Paddy Acc: 0.3223\n",
            "iou:0.2760 | Paddy iou: 0.2325 | Non-Paddy iou: 0.3195\n",
            "Valid Score Improved (0.4166 ---> 0.4308)\n",
            "EPOCH 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s, Loss=0.7107, gpu_mem=4.31 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.5s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "val: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, Loss=0.6180, gpu_mem=4.31 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.0s\n",
            "F1: 0.4694 | Paddy F1: 0.3540 | Non-Paddy F1: 0.5847 \n",
            "Acc:0.4944 | Paddy Acc: 0.7784 | Non-Paddy Acc: 0.4330\n",
            "iou:0.3141 | Paddy iou: 0.2151 | Non-Paddy iou: 0.4131\n",
            "Valid Score Improved (0.4308 ---> 0.4694)\n",
            "EPOCH 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "train: 100%|██████████| 7/7 [00:05<00:00,  1.30it/s, Loss=0.6571, gpu_mem=4.31 GB]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 5.5s\n",
            "Validation . . . \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "val: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it, Loss=0.6058, gpu_mem=4.31 GB]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch time : 1.3s\n",
            "F1: 0.4973 | Paddy F1: 0.3636 | Non-Paddy F1: 0.6310 \n",
            "Acc:0.5329 | Paddy Acc: 0.7500 | Non-Paddy Acc: 0.4859\n",
            "iou:0.3416 | Paddy iou: 0.2222 | Non-Paddy iou: 0.4609\n",
            "Valid Score Improved (0.4694 ---> 0.4973)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(CFG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "m19rwJncuZ86"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mhWHvUiaBptZ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
